"""See CallForest."""

from __future__ import annotations

import warnings
from pathlib import Path
from typing import Callable, Iterable, Mapping, Set, cast

import attr
import pandas as pd

from .util import flatten, normalize_cats, pd_read_sqlite_table


class DataIntegrityWarning(Warning):
    """Non-fatal warning that the data might be invalid."""


@attr.frozen
class Frame:
    """A stack frame."""

    tid: int = attr.ib()
    id: int = attr.ib()


@attr.frozen
class CallForest:
    """Deals with the callgraph (forest) generated by cpu_timer.

    Other analysis should never read the raw dataframe of cpu_timer
    frames; Instead, they should delegate to this module. That way, I
    can easily change how cpu_timer works.

    This will be based on implementation details of
    ILLIXR/common/cpu_timer and ILLIXR/runtime/frame_logger.hpp but
    NOT on any other part of ILLIXR.

    """

    _data: pd.DataFrame = attr.ib()
    roots: Set[Frame] = attr.ib()

    @classmethod
    def from_database(
        cls,
        database: Path,
        info_cols: Mapping[str, object],
        info_readers: Mapping[str, Callable[[pd.DataFrame], pd.DataFrame]],
        verify: bool = False,
    ) -> CallForest:
        """Reads a CallForest from the database

        This is the "opposite" of ILLIXR/runtime/frame_logger2.hpp.

        """
        strings = pd_read_sqlite_table(database, "strings", ["address"], verify)

        frames = (
            pd_read_sqlite_table(database, "finished", ["tid", "id"], verify)
            # replace function_name with a categorical
            # TODO: convert strings table to a pd.CategoricalDtype natively.
            .join(strings, on="function_name", how="left")
            .drop(columns=["function_name"])
            .assign(**{"function_name": lambda df: pd.Categorical(df["string"])})
            .drop(columns=["string"])
            # replace file_name with a categorical
            .join(strings, on="file_name", how="left")
            .drop(columns=["file_name"])
            .assign(**{"file_name": lambda df: pd.Categorical(df["string"])})
            .drop(columns=["string"])
            # add info columns
            .assign(**info_cols)
        )

        for function_name in frames["function_name"].drop_duplicates():
            info_readers.get(function_name, lambda df: df)(
                frames.loc[frames["function_name"] == function_name]
            )

        if verify:
            unique_static_sites = frames[
                ["function_name", "file_name", "line"]
            ].drop_duplicates()
            duplicates_by_function_name = ~unique_static_sites.duplicated(
                subset=["function_name"],
                keep=False,
            )
            if duplicates_by_function_name.any():
                warnings.warn(
                    "\n".join(
                        [
                            "The following are distinct static sites with the same function name.",
                            "I have treated them as the same static site for now.",
                            "If this is desired behavior, give them unique function names and merge them later on.",
                            str(unique_static_sites[duplicates_by_function_name]),
                        ]
                    ),
                    DataIntegrityWarning,
                )

        return cls(
            data=frames,
            roots=set(
                Frame(tid=cast(int, tid), id=0)
                for tid in cast(pd.MultiIndex, frames.index).levels[0].unique()
            ),
        )

    @classmethod
    def combine(cls, forests: Iterable[CallForest], verify: bool = False) -> CallForest:
        """Combine forests from multiple threads into one forest."""
        if not forests:
            raise ValueError("Must pass at least one forest to combine.")

        if verify:
            assert (
                # Pylint does not know that the type of forest is the class we are in.
                # pylint: disable=protected-access
                len(set(tuple(forest._data.columns) for forest in forests))
                < 1
            )

        return cls(
            data=pd.concat(
                normalize_cats(
                    # pylint: disable=protected-access
                    [forest._data for forest in forests],
                    include_indices=False,
                ),
                verify_integrity=verify,
            ),
            roots=set(flatten(forest.roots for forest in forests)),
        )

    @classmethod
    def from_dir(
        cls,
        metrics: Path,
        info_cols: Mapping[str, object],
        info_readers: Mapping[str, Callable[[pd.DataFrame], pd.DataFrame]],
        verify: bool = False,
    ) -> CallForest:
        """Returns a forest constructed from each database in the dir."""
        return cls.combine(
            [
                cls.from_database(database, info_cols, info_readers, verify)
                for database in (metrics / "frames").iterdir()
            ],
            verify,
        )
